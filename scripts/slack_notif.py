#!/usr/bin/env python3
# é‡èœä¾¡æ ¼äºˆæ¸¬ Slacké€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ  - BigQueryã®äºˆæ¸¬çµæœã‹ã‚‰å®‰ã„é‡èœã‚’é€šçŸ¥

import pandas as pd
import os
import json
import requests
import logging
import time
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Union, Any
from dataclasses import dataclass, asdict
from pathlib import Path
from google.cloud import bigquery
from google.cloud import storage
from google.api_core import exceptions as gcp_exceptions
from dotenv import load_dotenv
import psutil

# çµ±åˆãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s:%(lineno)d - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class SlackConfig:
    # Slacké€šçŸ¥è¨­å®š
    project_id: str
    dataset_prefix: str = "vege"
    environment: str = "dev"
    slack_webhook_url: Optional[str] = None
    gcs_bucket: Optional[str] = None
    price_decrease_threshold: float = 0.1  # 10%ä»¥ä¸Šã®ä¾¡æ ¼ä½ä¸‹
    min_confidence: float = 0.7  # æœ€ä½ä¿¡é ¼åº¦70%
    ml_prediction_status: str = "unknown"
    timeout_seconds: int = 30
    enable_debug: bool = False
    
    @classmethod
    def from_env(cls) -> 'SlackConfig':
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’ä½œæˆ
        load_dotenv()
        
        project_id = os.getenv("GCP_PROJECT_ID")
        if not project_id:
            raise ValueError("GCP_PROJECT_ID environment variable is required")
        
        return cls(
            project_id=project_id,
            dataset_prefix=os.getenv("DATASET_PREFIX", "vege"),
            environment=os.getenv("ENVIRONMENT", "dev"),
            slack_webhook_url=os.getenv("SLACK_WEBHOOK_URL"),
            gcs_bucket=os.getenv("GCS_BUCKET"),
            price_decrease_threshold=float(os.getenv("PRICE_DECREASE_THRESHOLD", "0.1")),
            min_confidence=float(os.getenv("MIN_CONFIDENCE", "0.7")),
            ml_prediction_status=os.getenv("ML_PREDICTION_STATUS", "unknown"),
            timeout_seconds=int(os.getenv("SLACK_TIMEOUT_SECONDS", "30")),
            enable_debug=os.getenv("SLACK_DEBUG", "false").lower() == "true"
        )

@dataclass
class NotificationResult:
    # é€šçŸ¥çµæœãƒ‡ãƒ¼ã‚¿
    success: bool
    target_month: int
    predictions_count: int
    model_available: bool
    duration_seconds: float
    timestamp: str
    message_preview: Optional[str] = None
    error: Optional[str] = None
    dry_run: bool = False


class EnhancedVegetablePriceNotifier:
    # æ”¹å–„ã•ã‚ŒãŸé‡èœä¾¡æ ¼äºˆæ¸¬ Slacké€šçŸ¥ã‚¯ãƒ©ã‚¹
    
    def __init__(self, config: SlackConfig):
        self.config = config
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        try:
            self.bq_client = bigquery.Client(project=config.project_id)
            self.storage_client = storage.Client(project=config.project_id) if config.gcs_bucket else None
        except Exception as e:
            self.logger.error(f"GCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise
        
        # Webhook URLæ¤œè¨¼
        if not config.slack_webhook_url:
            self.logger.warning("SLACK_WEBHOOK_URLç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™")
        
        # çµ±è¨ˆæƒ…å ±
        self.notifications_sent = 0
        self.last_notification_time = None
        
    def get_cheapest_vegetables_predictions(self, target_month: int = None) -> pd.DataFrame:
        # ç¾åœ¨æ—¥ä»˜ã®ç¿Œæœˆã®å®‰ã„é‡èœ TOP10ã‚’å–å¾—ï¼ˆæœ€æ–°ãƒ‡ãƒ¼ã‚¿æœˆã¨ã¯ç„¡é–¢ä¿‚ï¼‰
        if target_month is None:
            # ç¾åœ¨æ—¥ä»˜ã®ç¿Œæœˆã‚’ç®—å‡ºï¼ˆå›ºå®šï¼‰
            current_date = datetime.now()
            if current_date.month == 12:
                target_month = 1
                target_year = current_date.year + 1
            else:
                target_month = current_date.month + 1
                target_year = current_date.year
            
            self.logger.info(f"Slacké€šçŸ¥å¯¾è±¡: ç¾åœ¨æ—¥ä»˜({current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')})ã®ç¿Œæœˆ = {target_year}å¹´{target_month}æœˆ")
        else:
            target_year = datetime.now().year
            if target_month < datetime.now().month:
                target_year += 1
        
        self.logger.info(f"å®‰ã„é‡èœäºˆæ¸¬ã‚’å–å¾—ä¸­: {target_year}å¹´{target_month}æœˆ")
        self.logger.info(f"ç¾åœ¨æ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}, æ¤œç´¢å¯¾è±¡: {target_year}å¹´{target_month}æœˆã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿")
        
        # fact_price_predictionsãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª
        table_id = f"{self.config.project_id}.{self.config.dataset_prefix}_{self.config.environment}_mart.fact_price_predictions"
        try:
            table = self.bq_client.get_table(table_id)
            self.logger.info(f"äºˆæ¸¬ãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèª: {table.num_rows}è¡Œã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨")
        except Exception as e:
            self.logger.warning(f"äºˆæ¸¬ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
            self.logger.info("MLäºˆæ¸¬å‡¦ç†ãŒã¾ã å®Ÿè¡Œã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            return pd.DataFrame()
        
        query = f"""
        WITH latest_predictions AS (
          SELECT 
            item_name,
            model_type,
            predicted_price,
            last_actual_price,
            confidence_interval,
            prediction_reliability,
            model_r2,
            training_data_points,
            prediction_date,
            prediction_generated_at,
            ROW_NUMBER() OVER (
              PARTITION BY item_name 
              ORDER BY 
                -- MASEãŒä½ã„ã»ã©è‰¯ã„ï¼ˆãƒŠã‚¤ãƒ¼ãƒ–äºˆæ¸¬ã‚ˆã‚Šå„ªç§€ï¼‰
                CASE WHEN model_mae IS NOT NULL AND model_mae > 0 THEN model_mae ELSE 999 END ASC,
                -- sMAPEãŒä½ã„ã»ã©è‰¯ã„
                CASE WHEN model_smape IS NOT NULL AND model_smape > 0 THEN model_smape ELSE 999 END ASC,
                -- MAEãŒä½ã„ã»ã©è‰¯ã„
                CASE WHEN model_mae IS NOT NULL AND model_mae > 0 THEN model_mae ELSE 999 END ASC,
                -- æ—§æŒ‡æ¨™ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
                model_r2 DESC,
                CASE 
                  WHEN model_type = 'LSTM' THEN 1     -- LSTMã‚’å„ªå…ˆ
                  WHEN model_type = 'PROPHET' THEN 2  
                  WHEN model_type = 'ARIMA' THEN 3
                  ELSE 4
                END,
                prediction_generated_at DESC
            ) as rn
          FROM `{self.config.project_id}.{self.config.dataset_prefix}_{self.config.environment}_mart.fact_price_predictions`
          WHERE prediction_year = @target_year
            AND prediction_month = @target_month
            AND confidence_interval >= @min_confidence
            AND prediction_reliability IN ('HIGH', 'MEDIUM')
            AND training_data_points >= 24
            AND predicted_price > 0
            AND item_name NOT LIKE '%ãã®ä»–%'
            AND model_type IN ('PROPHET', 'LSTM', 'ARIMA')
        )
        
        SELECT 
          p.item_name,
          p.model_type,
          ROUND(p.predicted_price, 0) as predicted_price,
          ROUND(p.last_actual_price, 0) as current_price,
          NULL as price_change_pct,
          -- æ™‚ç³»åˆ—äºˆæ¸¬ç²¾åº¦è¡¨ç¤ºï¼ˆMASEåŸºæº–ï¼‰
          ROUND(
            CASE 
              WHEN p.model_mae IS NOT NULL AND p.model_mae > 0 THEN
                CASE 
                  WHEN p.model_mae < 20 THEN 95  -- EXCELLENT
                  WHEN p.model_mae < 50 THEN 85  -- GOOD  
                  WHEN p.model_mae < 100 THEN 75  -- FAIR
                  WHEN p.model_mae < 200 THEN 60  -- POOR
                  ELSE 40                          -- VERY_POOR
                END
              WHEN p.model_r2 IS NOT NULL AND p.model_r2 >= 0 THEN p.model_r2 * 100
              ELSE 0
            END, 0
          ) as confidence_pct,
          p.prediction_reliability,
          ROUND(COALESCE(p.model_mae, 999), 1) as model_mase,  -- åå‰ã¯model_maseã ãŒå®Ÿéš›ã¯MAEå€¤ã‚’ä½¿ç”¨
          ROUND(COALESCE(p.model_mae, 999), 1) as model_mae,
          ROUND(COALESCE(p.model_smape, 999), 1) as model_smape,
          p.training_data_points,
          p.prediction_date,
          DATE(p.prediction_generated_at) as generated_date
        FROM latest_predictions p
        WHERE p.rn = 1
        ORDER BY 
          p.predicted_price ASC,  -- æœ€ã‚‚å®‰ã„é †
          p.confidence_interval DESC,
          p.model_r2 DESC
        LIMIT 10
        """
        
        try:
            job_config = bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("target_year", "INT64", target_year),
                    bigquery.ScalarQueryParameter("target_month", "INT64", target_month),
                    bigquery.ScalarQueryParameter("min_confidence", "FLOAT64", self.config.min_confidence)
                ]
            )
            
            df = self.bq_client.query(query, job_config=job_config).to_dataframe()
            self.logger.info(f"å®‰ã„é‡èœäºˆæ¸¬å–å¾—å®Œäº†: {len(df)}å“ç›®")
            
            # å–å¾—ã—ãŸäºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
            if not df.empty:
                # prediction_dateã‚’datetimeå‹ã«æ˜ç¤ºçš„ã«å¤‰æ›
                df['prediction_date'] = pd.to_datetime(df['prediction_date'])
                unique_months = df['prediction_date'].dt.strftime('%Yå¹´%mæœˆ').unique()
                self.logger.info(f"å–å¾—ã—ãŸäºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®æœˆ: {', '.join(unique_months)}")
                self.logger.info(f"äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®å“ç›®: {', '.join(df['item_name'].unique()[:5])}...")
                
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæœˆãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
                target_month_str = f"{target_year}å¹´{target_month:02d}æœˆ"
                if target_month_str in unique_months:
                    self.logger.info(f"âœ… ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæœˆ({target_month_str})ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                else:
                    self.logger.warning(f"âš ï¸ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæœˆ({target_month_str})ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½: {', '.join(unique_months)}")
            else:
                self.logger.warning(f"{target_year}å¹´{target_month}æœˆã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
                # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®è©³ç´°èª¿æŸ»
                self.logger.info("äºˆæ¸¬ãƒ†ãƒ¼ãƒ–ãƒ«ã®å…¨ä½“ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªä¸­...")
                try:
                    # ã¾ãšRAWãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç¢ºèª
                    raw_check_query = f"""
                    SELECT 
                      prediction_year,
                      prediction_month,
                      COUNT(*) as count
                    FROM `{self.config.project_id}.{self.config.dataset_prefix}_{self.config.environment}_raw.ml_price_pred`
                    WHERE prediction_year >= {target_year - 1}
                    GROUP BY prediction_year, prediction_month
                    ORDER BY prediction_year, prediction_month
                    """
                    raw_df = self.bq_client.query(raw_check_query).to_dataframe()
                    if not raw_df.empty:
                        raw_months = raw_df.apply(lambda x: f"{int(x['prediction_year'])}å¹´{int(x['prediction_month']):02d}æœˆ({int(x['count'])}ä»¶)", axis=1).tolist()
                        self.logger.info(f"RAWãƒ†ãƒ¼ãƒ–ãƒ«(ml_price_pred)ã®ãƒ‡ãƒ¼ã‚¿: {', '.join(raw_months)}")
                    else:
                        self.logger.warning("RAWãƒ†ãƒ¼ãƒ–ãƒ«(ml_price_pred)ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                    
                    # æ¬¡ã«MARTãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç¢ºèª
                    mart_check_query = f"""
                    SELECT 
                      prediction_year,
                      prediction_month,
                      COUNT(*) as count
                    FROM `{self.config.project_id}.{self.config.dataset_prefix}_{self.config.environment}_mart.fact_price_predictions`
                    WHERE prediction_year >= {target_year - 1}
                    GROUP BY prediction_year, prediction_month
                    ORDER BY prediction_year, prediction_month
                    """
                    mart_df = self.bq_client.query(mart_check_query).to_dataframe()
                    if not mart_df.empty:
                        mart_months = mart_df.apply(lambda x: f"{int(x['prediction_year'])}å¹´{int(x['prediction_month']):02d}æœˆ({int(x['count'])}ä»¶)", axis=1).tolist()
                        self.logger.info(f"MARTãƒ†ãƒ¼ãƒ–ãƒ«(fact_price_predictions)ã®ãƒ‡ãƒ¼ã‚¿: {', '.join(mart_months)}")
                    else:
                        self.logger.warning("MARTãƒ†ãƒ¼ãƒ–ãƒ«(fact_price_predictions)ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                        
                        # RAWãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã€dbtå¤‰æ›ãŒå¤±æ•—ã—ã¦ã„ã‚‹
                        if not raw_df.empty:
                            self.logger.error("âš ï¸ dbtå¤‰æ›ã‚¨ãƒ©ãƒ¼: RAWãƒ‡ãƒ¼ã‚¿ã¯å­˜åœ¨ã™ã‚‹ãŒMARTãƒ†ãƒ¼ãƒ–ãƒ«ãŒç©ºã§ã™")
                            self.logger.error("stg_price_predictions ã¾ãŸã¯ fact_price_predictions ã®dbtãƒ¢ãƒ‡ãƒ«ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™")
                        
                except Exception as e:
                    self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
            
            return df
        except Exception as e:
            self.logger.error(f"å®‰ã„é‡èœäºˆæ¸¬å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    def get_seasonal_insights(self, target_month: int) -> Dict:
        # å­£ç¯€è¦å› ã«ã‚ˆã‚‹ä¾¡æ ¼å¤‰å‹•æ´å¯Ÿã‚’å–å¾—
        query = f"""
        SELECT 
          item_name,
          ROUND(AVG(avg_monthly_price), 0) as historical_avg_price,
          COUNT(*) as data_points,
          ROUND(STDDEV(avg_monthly_price), 0) as price_volatility
        FROM `{self.config.project_id}.{self.config.dataset_prefix}_{self.config.environment}_mart.mart_seasonal_analysis`
        WHERE month = @target_month
        GROUP BY item_name
        HAVING data_points >= 3
        ORDER BY price_volatility DESC
        """
        
        try:
            job_config = bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("target_month", "INT64", target_month)
                ]
            )
            
            df = self.bq_client.query(query, job_config=job_config).to_dataframe()
            
            insights = {
                'volatile_items': df.head(5)['item_name'].tolist(),
                'stable_items': df.tail(5)['item_name'].tolist(),
                'month_name': datetime(2023, target_month, 1).strftime('%mæœˆ')
            }
            
            self.logger.info(f"å­£ç¯€æ´å¯Ÿå–å¾—å®Œäº†: {target_month}æœˆã®{len(df)}å“ç›®")
            return insights
        except Exception as e:
            self.logger.error(f"å­£ç¯€æ´å¯Ÿå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def check_model_availability(self) -> Dict:
        # GCSã‹ã‚‰æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç”¨å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        if not self.config.gcs_bucket or not self.storage_client:
            return {'available': False, 'reason': 'GCS bucket not configured'}
        
        try:
            bucket = self.storage_client.bucket(self.config.gcs_bucket)
            
            # æœ€æ–°ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
            metadata_blobs = list(bucket.list_blobs(prefix='model-metadata/'))
            if not metadata_blobs:
                return {'available': False, 'reason': 'No model metadata found'}
            
            # æœ€æ–°ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            latest_blob = max(metadata_blobs, key=lambda x: x.time_created)
            metadata_content = latest_blob.download_as_text()
            metadata = json.loads(metadata_content)
            
            return {
                'available': True,
                'version': metadata.get('version'),
                'created_at': metadata.get('created_at'),
                'model_types': metadata.get('model_types', []),
                'items_covered': len(metadata.get('items_covered', [])),
                'gcs_path': f"gs://{self.config.gcs_bucket}/{latest_blob.name}"
            }
            
        except Exception as e:
            self.logger.error(f"ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return {'available': False, 'reason': f'Error: {str(e)}'}
    
    def create_slack_message(self, predictions_df: pd.DataFrame, target_month: int, 
                           seasonal_insights: Dict, model_info: Dict) -> Dict:
        # SlackæŠ•ç¨¿ç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
        month_name = datetime(2023, target_month, 1).strftime('%mæœˆ')
        
        if predictions_df.empty:
            # MLäºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®åˆ¤å®š
            if self.config.ml_prediction_status == 'failure':
                message_text = f"*{month_name}ã®ä¾¡æ ¼äºˆæ¸¬å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ* âŒ\n\næ¬¡å›ã®å‡¦ç†å®Ÿè¡Œã‚’ãŠå¾…ã¡ãã ã•ã„ã€‚"
            elif self.config.ml_prediction_status == 'success':
                # MLäºˆæ¸¬ã¯æˆåŠŸã—ãŸãŒdbtå¤‰æ›ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã‚‹å¯èƒ½æ€§
                message_text = f"*{month_name}ã®ä¾¡æ ¼äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™* âš ï¸\n\n"
                message_text += "MLäºˆæ¸¬ã¯æˆåŠŸã—ã¾ã—ãŸãŒã€dbtå¤‰æ›ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n"
                message_text += "ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ç¢ºèªã‚’ä¾é ¼ã—ã¦ãã ã•ã„ã€‚"
            elif not model_info.get('available', False):
                message_text = f"*{month_name}ã®ä¾¡æ ¼äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã æº–å‚™ä¸­ã§ã™* ğŸ”„\n\nMLäºˆæ¸¬å‡¦ç†ã®å®Œäº†ã‚’ãŠå¾…ã¡ãã ã•ã„ã€‚"
            else:
                message_text = f"*{month_name}ã®é‡èœä¾¡æ ¼äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒæº–å‚™ã§ãã¦ã„ã¾ã›ã‚“* ğŸ“Š\n\näºˆæ¸¬å‡¦ç†ã®å®Œäº†ã‚’ãŠå¾…ã¡ãã ã•ã„ã€‚"
            
            return {
                "text": f"ğŸ¥¬ {month_name}ã®å®‰ã„é‡èœTOP10",
                "blocks": [
                    {
                        "type": "header",
                        "text": {
                            "type": "plain_text",
                            "text": f"{month_name}ã®å®‰ã„é‡èœTOP10"
                        }
                    },
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": message_text
                        }
                    }
                ]
            }
        
        # ãƒ¡ã‚¤ãƒ³äºˆæ¸¬ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆå®‰ã„é‡èœTOP10ï¼‰
        predictions_text = ""
        for i, (_, row) in enumerate(predictions_df.head(10).iterrows(), 1):
            # MASEå€¤ã‹ã‚‰è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
            mase_detail = ""
            if 'model_mase' in row and row['model_mase'] != 999:
                if row['model_mase'] < 50:  # MAE < 50å††ã¯è‰¯å¥½
                    mase_detail = f" | äºˆæ¸¬èª¤å·® {row['model_mase']:.1f}å†† (è‰¯å¥½)"
                else:
                    mase_detail = f" | äºˆæ¸¬èª¤å·® {row['model_mase']:.1f}å††"
            
            predictions_text += (
                f"**{i}ä½: {row['item_name']}** - {int(row['predicted_price'])}å††/kg\n"
                f"ã€€äºˆæ¸¬ç²¾åº¦: {int(row['confidence_pct'])}% | {row['model_type']}{mase_detail}\n\n"
            )
        
        # å­£ç¯€æƒ…å ±
        seasonal_text = ""
        if seasonal_insights:
            if seasonal_insights.get('volatile_items'):
                seasonal_text = f"*{month_name}ã«ã‚ˆãå¤‰å‹•ã™ã‚‹é‡èœ*: " + "ã€".join(seasonal_insights['volatile_items'][:3])
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±
        model_text = ""
        if model_info.get('available'):
            model_text = (
                f"\n*äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æƒ…å ±*\n"
                f"ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {model_info['version']} | "
                f"å¯¾è±¡å“ç›®: {model_info['items_covered']}å“ç›® | "
                f"æ›´æ–°: {model_info['created_at'][:10]}"
            )
        
        return {
            "text": f"{month_name}ã®å®‰ã„é‡èœTOP10",
            "blocks": [
                {
                    "type": "header",
                    "text": {
                        "type": "plain_text",
                        "text": f"{month_name}ã®å®‰ä¾¡é‡èœTOP10"
                    }
                },
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"AIäºˆæ¸¬ã«ã‚ˆã‚‹{month_name}ã®é‡èœä¾¡æ ¼ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆå®‰ã„é †ï¼‰\n\n{predictions_text}"
                    }
                },
                {
                    "type": "divider"
                },
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"{seasonal_text}\n\n{model_text}"
                    }
                },
                {
                    "type": "context",
                    "elements": [
                        {
                            "type": "mrkdwn",
                            "text": f"äºˆæ¸¬ç”Ÿæˆæ—¥: {datetime.now().strftime('%Y-%m-%d')} | é‡èœå¸‚å ´åˆ†æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ "
                        }
                    ]
                }
            ]
        }
    
    def send_slack_notification(self, message: Dict) -> bool:
        # Slackã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
        if not self.config.slack_webhook_url:
            self.logger.error("Slack Webhook URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        try:
            headers = {
                'Content-Type': 'application/json; charset=utf-8'
            }
            
            response = requests.post(
                self.config.slack_webhook_url,
                headers=headers,
                data=json.dumps(message, ensure_ascii=False).encode('utf-8'),
                timeout=self.config.timeout_seconds
            )
            
            if response.status_code == 200:
                self.logger.info("Slacké€šçŸ¥é€ä¿¡æˆåŠŸ")
                self.notifications_sent += 1
                self.last_notification_time = datetime.now()
                return True
            else:
                self.logger.error(f"Slacké€šçŸ¥é€ä¿¡å¤±æ•—: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            self.logger.error(f"Slacké€šçŸ¥é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def run_notification(self, target_month: int = None, dry_run: bool = False) -> NotificationResult:
        # é€šçŸ¥å‡¦ç†ã‚’å®Ÿè¡Œ
        self.logger.info("=== é‡èœä¾¡æ ¼Slacké€šçŸ¥å‡¦ç†é–‹å§‹ ===")
        start_time = datetime.now()
        
        # ãƒ¡ãƒ¢ãƒªç›£è¦–
        initial_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        try:
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæœˆã®è¨­å®š
            if target_month is None:
                next_month = (datetime.now() + timedelta(days=30))
                target_month = next_month.month
            
            # å®‰ã„é‡èœäºˆæ¸¬ã‚’å–å¾—
            predictions_df = self.get_cheapest_vegetables_predictions(target_month)
            
            # å­£ç¯€æ´å¯Ÿã‚’å–å¾—
            seasonal_insights = self.get_seasonal_insights(target_month)
            
            # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—
            model_info = self.check_model_availability()
            
            # Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
            message = self.create_slack_message(
                predictions_df, target_month, seasonal_insights, model_info
            )
            
            # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ç¢ºèª
            if dry_run:
                self.logger.info("=== ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³: Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ ===")
                if self.config.enable_debug:
                    print(json.dumps(message, ensure_ascii=False, indent=2))
                self.logger.info("ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Œäº†ï¼ˆå®Ÿéš›ã®é€ä¿¡ã¯è¡Œã‚ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰")
                return NotificationResult(
                    success=True,
                    target_month=target_month,
                    predictions_count=len(predictions_df),
                    model_available=model_info.get('available', False),
                    duration_seconds=(datetime.now() - start_time).total_seconds(),
                    timestamp=datetime.now().isoformat(),
                    message_preview=message['text'],
                    dry_run=True
                )
            
            # Slacké€šçŸ¥é€ä¿¡
            success = self.send_slack_notification(message)
            
            # çµæœã‚µãƒãƒªãƒ¼
            end_time = datetime.now()
            current_memory = psutil.Process().memory_info().rss / 1024 / 1024
            
            summary = NotificationResult(
                success=success,
                target_month=target_month,
                predictions_count=len(predictions_df),
                model_available=model_info.get('available', False),
                duration_seconds=(end_time - start_time).total_seconds(),
                timestamp=datetime.now().isoformat()
            )
            
            if success:
                self.logger.info(f"âœ… é€šçŸ¥é€ä¿¡å®Œäº†: {len(predictions_df)}å“ç›®ã®ä¾¡æ ¼ä½ä¸‹äºˆæ¸¬")
            else:
                self.logger.error("âŒ é€šçŸ¥é€ä¿¡å¤±æ•—")
            
            self.logger.info(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {initial_memory:.1f}MB â†’ {current_memory:.1f}MB")
            
            return summary
            
        except Exception as e:
            self.logger.error(f"é€šçŸ¥å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return NotificationResult(
                success=False,
                target_month=target_month or 0,
                predictions_count=0,
                model_available=False,
                duration_seconds=(datetime.now() - start_time).total_seconds(),
                timestamp=datetime.now().isoformat(),
                error=str(e)
            )


def main():
    # ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    import argparse
    
    parser = argparse.ArgumentParser(description='é‡èœä¾¡æ ¼äºˆæ¸¬Slacké€šçŸ¥')
    parser.add_argument('--month', type=int, help='é€šçŸ¥å¯¾è±¡æœˆ (1-12)')
    parser.add_argument('--dry-run', action='store_true', help='ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆå®Ÿéš›ã®é€ä¿¡ãªã—ï¼‰')
    parser.add_argument('--threshold', type=float, default=0.1, help='ä¾¡æ ¼ä½ä¸‹é–¾å€¤ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.1 = 10%)')
    parser.add_argument('--confidence', type=float, default=0.7, help='æœ€ä½ä¿¡é ¼åº¦ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.7 = 70%)')
    
    args = parser.parse_args()
    
    try:
        # è¨­å®šèª­ã¿è¾¼ã¿
        config = SlackConfig.from_env()
        
        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ä¸Šæ›¸ã
        if args.threshold:
            config.price_decrease_threshold = args.threshold
        if args.confidence:
            config.min_confidence = args.confidence
        
        notifier = EnhancedVegetablePriceNotifier(config)
        result = notifier.run_notification(target_month=args.month, dry_run=args.dry_run)
        
        if result.success:
            print(f"âœ… é€šçŸ¥å‡¦ç†å®Œäº†")
            if not args.dry_run:
                print(f"ğŸ“± Slacké€šçŸ¥é€ä¿¡: {result.predictions_count}å“ç›®")
            exit(0)
        else:
            print(f"âŒ é€šçŸ¥å‡¦ç†å¤±æ•—: {result.error or 'Unknown error'}")
            exit(1)
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        exit(1)


if __name__ == "__main__":
    main()