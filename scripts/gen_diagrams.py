#!/usr/bin/env python3
"""
é‡èœå¸‚å ´åˆ†æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  - åŒ…æ‹¬çš„å›³è¡¨ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 

æ”¹å–„ç‚¹:
- å‹ãƒ’ãƒ³ãƒˆã¨ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã§ã®è¨­å®šç®¡ç†
- åŒ…æ‹¬çš„ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ­ã‚°æ”¹å–„
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ã®ä¾å­˜é–¢ä¿‚ç®¡ç†
"""

import os
import logging
import time
import argparse
from datetime import datetime
from typing import Dict, List, Optional, Union, Any, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
from dotenv import load_dotenv
import psutil

# æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - Diagramsãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    from diagrams import Diagram, Cluster, Node, Edge
    
    # GCP ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆå…¬å¼ã‚¢ã‚¤ã‚³ãƒ³ï¼‰
    from diagrams.gcp.analytics import Bigquery, Dataflow, Pubsub, Dataproc
    from diagrams.gcp.compute import AppEngine, Functions, ComputeEngine, KubernetesEngine
    from diagrams.gcp.storage import Storage as GCS
    from diagrams.gcp.ml import AIPlatform, Automl
    
    # ã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹ãƒ»æ±ç”¨ã‚µãƒ¼ãƒ“ã‚¹  
    from diagrams.onprem.client import Users
    from diagrams.onprem.compute import Server
    from diagrams.onprem.inmemory import Redis
    from diagrams.onprem.network import Internet
    from diagrams.onprem.workflow import Airflow
    from diagrams.onprem.analytics import Dbt
    from diagrams.onprem.monitoring import Grafana
    
    # ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªãƒ»ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
    from diagrams.programming.language import Python
    from diagrams.programming.framework import FastAPI
    
    # æ±ç”¨ã‚¢ã‚¤ã‚³ãƒ³
    from diagrams.generic.storage import Storage
    from diagrams.generic.database import SQL
    from diagrams.generic.compute import Rack
    from diagrams.generic.blank import Blank
    
    DIAGRAMS_AVAILABLE = True
    
except ImportError as e:
    logging.warning(f"Diagrams library not available: {e}")
    DIAGRAMS_AVAILABLE = False

# çµ±åˆãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s:%(lineno)d - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class DiagramConfig:
    """å›³è¡¨ç”Ÿæˆè¨­å®š"""
    output_dir: str = "../docs/images"
    image_format: str = "png"
    enable_show: bool = False
    default_direction: str = "TB"
    font_size: str = "40"
    node_sep: str = "1.5"
    rank_sep: str = "2.0"
    pad: str = "1.0"
    splines: str = "ortho"
    overlap: str = "false"
    compound: str = "true"
    enable_performance_monitoring: bool = True
    timeout_seconds: int = 300
    
    @classmethod
    def from_env(cls) -> 'DiagramConfig':
        """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’ä½œæˆ"""
        load_dotenv()
        
        return cls(
            output_dir=os.getenv("DIAGRAM_OUTPUT_DIR", "../docs/images"),
            image_format=os.getenv("DIAGRAM_FORMAT", "png"),
            enable_show=os.getenv("DIAGRAM_SHOW", "false").lower() == "true",
            default_direction=os.getenv("DIAGRAM_DIRECTION", "TB"),
            font_size=os.getenv("DIAGRAM_FONT_SIZE", "40"),
            enable_performance_monitoring=os.getenv("ENABLE_PERFORMANCE_MONITORING", "true").lower() == "true",
            timeout_seconds=int(os.getenv("DIAGRAM_TIMEOUT_SECONDS", "300"))
        )

@dataclass
class DiagramResult:
    """å›³è¡¨ç”Ÿæˆçµæœãƒ‡ãƒ¼ã‚¿"""
    success: bool
    diagram_name: str
    file_path: Optional[str] = None
    generation_time_seconds: float = 0.0
    error: Optional[str] = None


class EnhancedDiagramGenerator:
    """æ”¹å–„ã•ã‚ŒãŸå›³è¡¨ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: DiagramConfig):
        self.config = config
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
        if not DIAGRAMS_AVAILABLE:
            raise RuntimeError("Diagrams library is not available. Please install: pip install diagrams")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        try:
            os.makedirs(config.output_dir, exist_ok=True)
            self.logger.info(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™å®Œäº†: {config.output_dir}")
        except Exception as e:
            self.logger.error(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise
        
        # çµ±è¨ˆæƒ…å ±
        self.diagrams_generated = 0
        self.total_generation_time = 0.0
        self.generation_start_time = None
        
    def get_default_graph_attr(self, **overrides) -> Dict[str, str]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚°ãƒ©ãƒ•å±æ€§ã‚’å–å¾—"""
        default_attr = {
            "fontsize": self.config.font_size,
            "nodesep": self.config.node_sep,
            "ranksep": self.config.rank_sep,
            "pad": self.config.pad,
            "splines": self.config.splines,
            "overlap": self.config.overlap,
            "compound": self.config.compound
        }
        default_attr.update(overrides)
        return default_attr
    
    def _generate_diagram_with_monitoring(self, diagram_func, diagram_name: str, **kwargs) -> DiagramResult:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ä»˜ãã§å›³è¡¨ã‚’ç”Ÿæˆ"""
        start_time = time.time()
        initial_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        try:
            self.logger.info(f"{diagram_name}ã®ç”Ÿæˆã‚’é–‹å§‹...")
            result = diagram_func(**kwargs)
            generation_time = time.time() - start_time
            
            current_memory = psutil.Process().memory_info().rss / 1024 / 1024
            
            self.logger.info(f"{diagram_name}ç”Ÿæˆå®Œäº†: {generation_time:.2f}ç§’")
            
            if self.config.enable_performance_monitoring:
                self.logger.info(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {initial_memory:.1f}MB â†’ {current_memory:.1f}MB")
            
            self.diagrams_generated += 1
            self.total_generation_time += generation_time
            
            return DiagramResult(
                success=True,
                diagram_name=diagram_name,
                file_path=result,
                generation_time_seconds=generation_time
            )
            
        except Exception as e:
            generation_time = time.time() - start_time
            self.logger.error(f"{diagram_name}ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            
            return DiagramResult(
                success=False,
                diagram_name=diagram_name,
                generation_time_seconds=generation_time,
                error=str(e)
            )
    
    def generate_overall_architecture(self) -> str:
        """å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³ã‚’ç”Ÿæˆ"""
        filename = f"{self.config.output_dir}/overall_architecture_v2"
        
        with Diagram("Vegetable Market Analysis Platform - Overall Architecture", 
                     filename=filename, 
                     show=self.config.enable_show, 
                     direction=self.config.default_direction, 
                     graph_attr=self.get_default_graph_attr(
                         fontsize="45",
                         nodesep="1.5",
                         ranksep="2.0"
                     )):
            
            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å±¤
            with Cluster("Data Sources", graph_attr={"style": "rounded", "bgcolor": "lightblue"}):
                market_web = Internet("Market Data\nWebsite (Excel)")
                jma_api = Internet("JMA Weather\nAPI (JSON)")
            
            # ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»å‡¦ç†å±¤
            with Cluster("Data Collection & Processing", graph_attr={"style": "rounded", "bgcolor": "lightgreen"}):
                vege_collector = Python("get_vege_data.py")
                weather_collector = Python("get_weather_data.py")
                
            # Google Cloud Platform
            with Cluster("Google Cloud Platform", graph_attr={"style": "rounded", "bgcolor": "lightyellow"}):
                # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ¬ã‚¤ãƒ¤ãƒ¼
                with Cluster("Storage Layer"):
                    gcs_raw = GCS("Raw Data\n(CSV Files)")
                
                # BigQuery ãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹
                with Cluster("BigQuery Data Warehouse"):
                    with Cluster("RAW Layer"):
                        bq_raw_market = Bigquery("${BQ_TABLE}")
                        bq_raw_weather = Bigquery("weather_hourly")
                    
                    with Cluster("STG Layer (dbt)"):
                        bq_stg_market = Bigquery("stg_market_raw")
                        bq_stg_weather = Bigquery("stg_weather_observation")
                        
                    with Cluster("MART Layer (dbt)"):
                        bq_dims = Bigquery("Dimensions\n(5 tables)")
                        bq_facts = Bigquery("Facts\n(2 tables)")
                        bq_marts = Bigquery("Analysis Marts\n(4 tables)")
                
                # dbtå¤‰æ›ã‚¨ãƒ³ã‚¸ãƒ³
                dbt_runner = Dataflow("dbt Transformations")
            
            # åˆ†æãƒ»æ©Ÿæ¢°å­¦ç¿’å±¤
            with Cluster("Analytics & ML", graph_attr={"style": "rounded", "bgcolor": "lightcoral"}):
                ml_models = AIPlatform("ML Models\n(Prophet/LSTM/ARIMA)")
                api_service = AppEngine("Prediction API\n(FastAPI)")
                model_cache = Redis("Model Cache")
                
            # å¯è¦–åŒ–ãƒ»ãƒ¬ãƒãƒ¼ãƒˆå±¤
            with Cluster("Visualization & Reporting", graph_attr={"style": "rounded", "bgcolor": "lightpink"}):
                looker_dashboard = Server("Looker Studio\nDashboards")
                users = Users("Business Users")
                
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ï¼ˆã‚¨ãƒƒã‚¸ãƒ©ãƒ™ãƒ«ä»˜ãï¼‰
            market_web >> Edge(label="Monthly Excel\nDownload", style="bold", color="blue") >> vege_collector
            jma_api >> Edge(label="Hourly Weather\nData API", style="bold", color="blue") >> weather_collector
            
            vege_collector >> Edge(label="CSV Upload", style="dashed", color="green") >> gcs_raw
            weather_collector >> Edge(label="CSV Upload", style="dashed", color="green") >> gcs_raw
            
            gcs_raw >> Edge(label="Batch Load", style="solid", color="orange") >> bq_raw_market
            gcs_raw >> Edge(label="Batch Load", style="solid", color="orange") >> bq_raw_weather
            
            bq_raw_market >> Edge(label="dbt run", style="bold", color="purple") >> dbt_runner
            bq_raw_weather >> Edge(label="dbt run", style="bold", color="purple") >> dbt_runner
            
            dbt_runner >> Edge(label="Transform", style="solid", color="red") >> bq_stg_market
            dbt_runner >> Edge(label="Transform", style="solid", color="red") >> bq_stg_weather
            bq_stg_market >> Edge(label="Aggregate", style="dotted", color="darkgreen") >> bq_dims
            bq_stg_market >> Edge(label="Aggregate", style="dotted", color="darkgreen") >> bq_facts
            bq_stg_weather >> Edge(label="Aggregate", style="dotted", color="darkgreen") >> bq_marts
            
            bq_marts >> Edge(label="Training Data", style="bold", color="darkred") >> ml_models
            ml_models >> Edge(label="Model Deploy", style="dashed", color="darkblue") >> api_service
            api_service >> Edge(label="Cache", style="dotted", color="gray") >> model_cache
            
            bq_marts >> Edge(label="Analytics", style="solid", color="darkviolet") >> looker_dashboard
            looker_dashboard >> Edge(label="Reports", style="bold", color="black") >> users
        
        return f"{filename}.{self.config.image_format}"
    
    def generate_data_pipeline_architecture(self) -> str:
        """ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©³ç´°å›³ã‚’ç”Ÿæˆ"""
        filename = f"{self.config.output_dir}/data_pipeline_architecture_v2"
        
        with Diagram("Data Pipeline Detailed Architecture", 
                     filename=filename, 
                     show=self.config.enable_show, 
                     direction=self.config.default_direction, 
                     graph_attr=self.get_default_graph_attr(
                         nodesep="2.5",
                         ranksep="3.5",
                         pad="2.0",
                         concentrate="true"
                     )):
            
            # ç¬¬1å±¤: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
            with Cluster("ğŸŒ External Data Sources", graph_attr={"style": "rounded", "bgcolor": "lightblue", "margin": "20"}):
                market_site = Internet("Market Data\nWebsite")
                jma_api = Internet("JMA Weather\nAPI")
                
            # ç¬¬2å±¤: ãƒ‡ãƒ¼ã‚¿åé›†
            with Cluster("ğŸ“¥ Data Collection Layer", graph_attr={"style": "rounded", "bgcolor": "lightgreen", "margin": "20"}):
                market_collector = Python("Market Data\nCollector")
                weather_collector = Python("Weather Data\nCollector")
            
            # ç¬¬3å±¤: ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»å¤‰æ›
            with Cluster("Data Processing Layer", graph_attr={"style": "rounded", "bgcolor": "lightyellow", "margin": "20"}):
                market_processor = Python("Market ETL\nProcessor")
                weather_processor = Python("Weather ETL\nProcessor")
                
            # ç¬¬4å±¤: ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
            with Cluster("Cloud Storage Layer", graph_attr={"style": "rounded", "bgcolor": "lightcyan", "margin": "20"}):
                gcs_storage = GCS("Raw Data Storage\n(CSV Files)")
                
            # ç¬¬5å±¤: BigQuery RAWå±¤
            with Cluster("BigQuery RAW Layer", graph_attr={"style": "rounded", "bgcolor": "wheat", "margin": "20"}):
                raw_market_table = Bigquery("${BQ_TABLE}\n(Raw Data)")
                raw_weather_table = Bigquery("weather_hourly\n(Raw Data)")
            
            # ç¬¬6å±¤: dbtå¤‰æ›ã‚¨ãƒ³ã‚¸ãƒ³
            dbt_engine = Dataflow("dbt Transformation\nEngine")
                
            # ç¬¬7å±¤: BigQueryå¤‰æ›æ¸ˆã¿å±¤
            with Cluster("BigQuery Transformed Layers", graph_attr={"style": "rounded", "bgcolor": "lightpink", "margin": "20"}):
                with Cluster("STG Layer", graph_attr={"style": "dotted", "bgcolor": "mistyrose"}):
                    stg_market_table = Bigquery("stg_market_raw")
                    stg_weather_table = Bigquery("stg_weather_observation")
                    
                with Cluster("MART Layer", graph_attr={"style": "dotted", "bgcolor": "lavenderblush"}):
                    mart_dims = Bigquery("Dimensions\n(5 tables)")
                    mart_facts = Bigquery("Facts\n(2 tables)")
                    mart_analysis = Bigquery("Analysis Marts\n(4 tables)")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ï¼ˆéšå±¤åˆ¥ãƒ»è‰²åˆ†ã‘ï¼‰
            market_site >> Edge(label="Excel Download", style="bold", color="blue") >> market_collector
            jma_api >> Edge(label="API Call", style="bold", color="blue") >> weather_collector
            
            market_collector >> Edge(label="Parse & Validate", style="solid", color="green") >> market_processor
            weather_collector >> Edge(label="Normalize & Clean", style="solid", color="green") >> weather_processor
            
            market_processor >> Edge(label="CSV Upload", style="dashed", color="orange") >> gcs_storage
            weather_processor >> Edge(label="CSV Upload", style="dashed", color="orange") >> gcs_storage
            
            gcs_storage >> Edge(label="Batch Load", style="solid", color="purple") >> raw_market_table
            gcs_storage >> Edge(label="Batch Load", style="solid", color="purple") >> raw_weather_table
            
            raw_market_table >> Edge(label="dbt Source", style="bold", color="red") >> dbt_engine
            raw_weather_table >> Edge(label="dbt Source", style="bold", color="red") >> dbt_engine
            
            dbt_engine >> Edge(label="STG Transform", style="dotted", color="darkgreen") >> stg_market_table
            dbt_engine >> Edge(label="STG Transform", style="dotted", color="darkgreen") >> stg_weather_table
            dbt_engine >> Edge(label="MART Build", style="solid", color="darkred") >> mart_dims
            dbt_engine >> Edge(label="MART Build", style="solid", color="darkred") >> mart_facts
            dbt_engine >> Edge(label="MART Build", style="solid", color="darkred") >> mart_analysis
        
        return f"{filename}.{self.config.image_format}"
    
    def generate_ml_architecture(self) -> str:
        """æ©Ÿæ¢°å­¦ç¿’ãƒ»äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ è©³ç´°å›³ã‚’ç”Ÿæˆ"""
        filename = f"{self.config.output_dir}/ml_architecture_v2"
        
        with Diagram("ML Prediction System Architecture", 
                     filename=filename, 
                     show=self.config.enable_show, 
                     direction=self.config.default_direction, 
                     graph_attr=self.get_default_graph_attr(
                         fontsize="45",
                         nodesep="2.0",
                         ranksep="2.8",
                         pad="1.5"
                     )):
            
            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å±¤
            with Cluster("BigQuery Data Marts"):
                price_weather_mart = Bigquery("mart_price_weather\nIntegrated Analysis")
                seasonal_mart = Bigquery("mart_seasonal_analysis\nSeasonality Patterns")
            
            # æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
            with Cluster("ML Pipeline"):
                # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
                data_processor = ComputeEngine("Feature Engineering\n& Data Preprocessing")
                
                # ãƒ¢ãƒ‡ãƒ«ç¾¤
                with Cluster("Time Series Models"):
                    prophet_model = AIPlatform("Prophet Model\n(Facebook)")
                    lstm_model = AIPlatform("LSTM Model\n(Deep Learning)")
                    arima_model = AIPlatform("ARIMA Model\n(Statistics)")
                    
                # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ»é¸æŠ
                model_evaluator = AIPlatform("Model Evaluation\n& Selection")
                hyperparameter_tuner = Automl("Hyperparameter\nTuning")
            
            # äºˆæ¸¬APIã‚µãƒ¼ãƒ“ã‚¹å±¤
            with Cluster("Prediction API Service"):
                prediction_api = AppEngine("FastAPI Server\nPrediction Endpoints")
                model_store = GCS("Model Storage\n(Trained Models)")
                cache_layer = Redis("Prediction Cache\n(Redis)")
                
            # åˆ©ç”¨è€…ãƒ»ã‚·ã‚¹ãƒ†ãƒ å±¤
            with Cluster("Users & Systems"):
                api_clients = Users("API Clients")
                dashboard_users = Users("Dashboard Users")
                business_analysts = Users("Business Analysts")
                
            # CI/CD & Monitoring
            with Cluster("Operations"):
                model_monitor = Server("Model Monitoring\n& Alerts")
                
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ï¼ˆã‚¨ãƒƒã‚¸ãƒ©ãƒ™ãƒ«ä»˜ãï¼‰
            price_weather_mart >> Edge(label="Training Data") >> data_processor
            seasonal_mart >> Edge(label="Feature Data") >> data_processor
            
            data_processor >> Edge(label="Processed Features") >> prophet_model
            data_processor >> Edge(label="Processed Features") >> lstm_model
            data_processor >> Edge(label="Processed Features") >> arima_model
            
            prophet_model >> Edge(label="Model Outputs") >> model_evaluator
            lstm_model >> Edge(label="Model Outputs") >> model_evaluator
            arima_model >> Edge(label="Model Outputs") >> model_evaluator
            model_evaluator >> Edge(label="Best Model") >> hyperparameter_tuner
            
            hyperparameter_tuner >> Edge(label="Optimized Model") >> model_store
            model_store >> Edge(label="Load Model") >> prediction_api
            
            prediction_api >> Edge(label="Cache Results") >> cache_layer
            
            api_clients >> Edge(label="API Requests") >> prediction_api
            prediction_api >> Edge(label="Predictions") >> api_clients
            
            dashboard_users >> Edge(label="Analytics Query") >> price_weather_mart
            business_analysts >> Edge(label="Reports") >> seasonal_mart
            
            prediction_api >> Edge(label="Metrics") >> model_monitor
        
        return f"{filename}.{self.config.image_format}"
    
    def generate_all_diagrams(self) -> List[DiagramResult]:
        """å…¨ã¦ã®å›³è¡¨ã‚’ç”Ÿæˆ"""
        self.logger.info("=== åŒ…æ‹¬çš„å›³è¡¨ç”Ÿæˆã‚’é–‹å§‹ ===")
        self.generation_start_time = datetime.now()
        
        # ãƒ¡ãƒ¢ãƒªç›£è¦–
        initial_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        results = []
        
        # å›³è¡¨ç”Ÿæˆé–¢æ•°ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        diagram_generators = {
            "Overall Architecture": self.generate_overall_architecture,
            "Data Pipeline Architecture": self.generate_data_pipeline_architecture,
            "ML Architecture": self.generate_ml_architecture,
        }
        
        for diagram_name, generator_func in diagram_generators.items():
            result = self._generate_diagram_with_monitoring(
                generator_func, diagram_name
            )
            results.append(result)
            
            if not result.success:
                self.logger.warning(f"{diagram_name}ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸãŒã€å‡¦ç†ã‚’ç¶™ç¶šã—ã¾ã™")
        
        # çµæœã‚µãƒãƒªãƒ¼
        end_time = datetime.now()
        duration = end_time - self.generation_start_time
        current_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        successful_diagrams = [r for r in results if r.success]
        failed_diagrams = [r for r in results if not r.success]
        
        self.logger.info(f"=== å›³è¡¨ç”Ÿæˆå®Œäº† ===")
        self.logger.info(f"æˆåŠŸ: {len(successful_diagrams)}/{len(results)}å›³è¡¨")
        self.logger.info(f"ç·å‡¦ç†æ™‚é–“: {duration.total_seconds():.2f}ç§’")
        self.logger.info(f"å¹³å‡ç”Ÿæˆæ™‚é–“: {self.total_generation_time/len(results):.2f}ç§’/å›³è¡¨")
        
        if self.config.enable_performance_monitoring:
            self.logger.info(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {initial_memory:.1f}MB â†’ {current_memory:.1f}MB")
        
        if failed_diagrams:
            self.logger.warning(f"å¤±æ•—ã—ãŸå›³è¡¨: {[d.diagram_name for d in failed_diagrams]}")
        
        return results


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description="é‡èœå¸‚å ´åˆ†æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å›³è¡¨ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ")
    
    parser.add_argument("--output-dir", help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--show", action="store_true", help="ç”Ÿæˆå¾Œã«å›³è¡¨ã‚’è¡¨ç¤º")
    parser.add_argument("--format", choices=["png", "jpg", "svg", "pdf"], default="png", help="å‡ºåŠ›å½¢å¼")
    parser.add_argument("--disable-monitoring", action="store_true", help="ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚’ç„¡åŠ¹åŒ–")
    parser.add_argument("--timeout", type=int, help="ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç§’æ•°")
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("é‡èœå¸‚å ´åˆ†æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å›³è¡¨ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆé«˜æ€§èƒ½ç‰ˆï¼‰")
    print("=" * 80)
    
    try:
        # è¨­å®šèª­ã¿è¾¼ã¿
        config = DiagramConfig.from_env()
        
        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ä¸Šæ›¸ã
        if args.output_dir:
            config.output_dir = args.output_dir
        if args.show:
            config.enable_show = True
        if args.format:
            config.image_format = args.format
        if args.disable_monitoring:
            config.enable_performance_monitoring = False
        if args.timeout:
            config.timeout_seconds = args.timeout
        
        # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–
        generator = EnhancedDiagramGenerator(config)
        
        print(f"å®Ÿè¡Œè¨­å®š:")
        print(f"  å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {config.output_dir}")
        print(f"  å‡ºåŠ›å½¢å¼: {config.image_format}")
        print(f"  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–: {'ON' if config.enable_performance_monitoring else 'OFF'}")
        print(f"  ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {config.timeout_seconds}ç§’")
        print()
        
        # å›³è¡¨ç”Ÿæˆå®Ÿè¡Œ
        results = generator.generate_all_diagrams()
        
        # çµæœè¡¨ç¤º
        successful_diagrams = [r for r in results if r.success]
        failed_diagrams = [r for r in results if not r.success]
        
        if successful_diagrams:
            print("[OK] ç”ŸæˆæˆåŠŸ:")
            for result in successful_diagrams:
                print(f"  - {result.diagram_name}: {result.file_path}")
        
        if failed_diagrams:
            print("[ERROR] ç”Ÿæˆå¤±æ•—:")
            for result in failed_diagrams:
                print(f"  - {result.diagram_name}: {result.error}")
        
        if len(successful_diagrams) == len(results):
            print(f"\nğŸ‰ å…¨ã¦ã®å›³è¡¨ãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼")
            return 0
        elif successful_diagrams:
            print(f"\n[WARNING] éƒ¨åˆ†çš„æˆåŠŸ: {len(successful_diagrams)}/{len(results)}å›³è¡¨")
            return 1
        else:
            print(f"\nğŸ’¥ å…¨ã¦ã®å›³è¡¨ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return 1
            
    except Exception as e:
        logger.error(f"å›³è¡¨ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print(f"[ERROR] ã‚¨ãƒ©ãƒ¼: {e}")
        print("\n[NOTE] æ³¨æ„: GraphvizãŒã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        print("[INFO] Graphvizã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: https://graphviz.org/download/")
        print("[INFO] pip install diagrams graphviz")
        return 1


if __name__ == "__main__":
    exit(main())